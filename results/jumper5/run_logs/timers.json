{
    "name": "root",
    "gauges": {
        "Evader.Policy.Entropy.mean": {
            "value": 0.014873937703669071,
            "min": 0.00010284534801030532,
            "max": 0.026902267709374428,
            "count": 21
        },
        "Evader.Policy.Entropy.sum": {
            "value": 29.495018005371094,
            "min": 0.20404517650604248,
            "max": 29.495018005371094,
            "count": 21
        },
        "Evader.Step.mean": {
            "value": 2041936.0,
            "min": 2001985.0,
            "max": 2041936.0,
            "count": 21
        },
        "Evader.Step.sum": {
            "value": 2041936.0,
            "min": 2001985.0,
            "max": 2041936.0,
            "count": 21
        },
        "Evader.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.017459850758314133,
            "min": -3.692416191101074,
            "max": -0.017459850758314133,
            "count": 21
        },
        "Evader.Policy.ExtrinsicValueEstimate.sum": {
            "value": -0.5412553548812866,
            "min": -118.15731811523438,
            "max": -0.5412553548812866,
            "count": 21
        },
        "Evader.Environment.EpisodeLength.mean": {
            "value": 1854.0,
            "min": 164.0,
            "max": 6961.0,
            "count": 10
        },
        "Evader.Environment.EpisodeLength.sum": {
            "value": 1854.0,
            "min": 164.0,
            "max": 12207.0,
            "count": 10
        },
        "Evader.Environment.CumulativeReward.mean": {
            "value": -21.600000381469727,
            "min": -21.600000381469727,
            "max": -5.199999809265137,
            "count": 10
        },
        "Evader.Environment.CumulativeReward.sum": {
            "value": -21.600000381469727,
            "min": -30.30000051856041,
            "max": -5.199999809265137,
            "count": 10
        },
        "Evader.Policy.ExtrinsicReward.mean": {
            "value": -21.600000381469727,
            "min": -21.600000381469727,
            "max": -5.199999809265137,
            "count": 10
        },
        "Evader.Policy.ExtrinsicReward.sum": {
            "value": -21.600000381469727,
            "min": -30.30000051856041,
            "max": -5.199999809265137,
            "count": 10
        },
        "Evader.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 21
        },
        "Evader.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 21
        },
        "Evader.Losses.PolicyLoss.mean": {
            "value": 0.3063328539331754,
            "min": 0.0435300933662802,
            "max": 0.3063328539331754,
            "count": 7
        },
        "Evader.Losses.PolicyLoss.sum": {
            "value": 0.3063328539331754,
            "min": 0.0435300933662802,
            "max": 0.3063328539331754,
            "count": 7
        },
        "Evader.Losses.ValueLoss.mean": {
            "value": 1.6265618396302064,
            "min": 0.058916030700008074,
            "max": 1.6265618396302064,
            "count": 7
        },
        "Evader.Losses.ValueLoss.sum": {
            "value": 1.6265618396302064,
            "min": 0.058916030700008074,
            "max": 1.6265618396302064,
            "count": 7
        },
        "Evader.Policy.LearningRate.mean": {
            "value": 0.00023887712037429993,
            "min": 0.00023887712037429993,
            "max": 0.00023980490006503998,
            "count": 7
        },
        "Evader.Policy.LearningRate.sum": {
            "value": 0.00023887712037429993,
            "min": 0.00023887712037429993,
            "max": 0.00023980490006503998,
            "count": 7
        },
        "Evader.Policy.Epsilon.mean": {
            "value": 0.17962570000000005,
            "min": 0.17962570000000005,
            "max": 0.17993496000000006,
            "count": 7
        },
        "Evader.Policy.Epsilon.sum": {
            "value": 0.17962570000000005,
            "min": 0.17962570000000005,
            "max": 0.17993496000000006,
            "count": 7
        },
        "Evader.Policy.Beta.mean": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005,
            "count": 7
        },
        "Evader.Policy.Beta.sum": {
            "value": 0.0005,
            "min": 0.0005,
            "max": 0.0005,
            "count": 7
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1682102170",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\UnityProjects\\My project\\venv\\Scripts\\mlagents-learn --run-id=jumper5 config\\Evader.yaml --resume",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1682102497"
    },
    "total": 326.9576544,
    "count": 1,
    "self": 0.004519700000059856,
    "children": {
        "run_training.setup": {
            "total": 0.14022230000000002,
            "count": 1,
            "self": 0.14022230000000002
        },
        "TrainerController.start_learning": {
            "total": 326.81291239999996,
            "count": 1,
            "self": 0.6810593999988441,
            "children": {
                "TrainerController._reset_env": {
                    "total": 7.3901953,
                    "count": 1,
                    "self": 7.3901953
                },
                "TrainerController.advance": {
                    "total": 318.6717067000011,
                    "count": 42546,
                    "self": 0.6485164000000623,
                    "children": {
                        "env_step": {
                            "total": 304.0159519,
                            "count": 42546,
                            "self": 177.17420100000402,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 126.41409149999632,
                                    "count": 42546,
                                    "self": 2.188002799995914,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 124.2260887000004,
                                            "count": 42532,
                                            "self": 124.2260887000004
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.4276593999996585,
                                    "count": 42545,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 319.44719370000035,
                                            "count": 42545,
                                            "is_parallel": true,
                                            "self": 173.3731538999966,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003353999999999857,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00016230000000039269,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00017309999999959302,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00017309999999959302
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 146.07370440000375,
                                                    "count": 42545,
                                                    "is_parallel": true,
                                                    "self": 2.7620350000003384,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 2.3656324000046265,
                                                            "count": 42545,
                                                            "is_parallel": true,
                                                            "self": 2.3656324000046265
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 130.93581879999923,
                                                            "count": 42545,
                                                            "is_parallel": true,
                                                            "self": 130.93581879999923
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 10.010218199999573,
                                                            "count": 42545,
                                                            "is_parallel": true,
                                                            "self": 5.199375500004381,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4.810842699995192,
                                                                    "count": 170180,
                                                                    "is_parallel": true,
                                                                    "self": 4.810842699995192
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 14.007238400001011,
                            "count": 42545,
                            "self": 0.8302710999991483,
                            "children": {
                                "process_trajectory": {
                                    "total": 3.6587755000018447,
                                    "count": 42545,
                                    "self": 3.6587755000018447
                                },
                                "_update_policy": {
                                    "total": 9.518191800000018,
                                    "count": 8,
                                    "self": 4.779436100000105,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 4.738755699999913,
                                            "count": 480,
                                            "self": 4.738755699999913
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.000000093488779e-07,
                    "count": 1,
                    "self": 8.000000093488779e-07
                },
                "TrainerController._save_models": {
                    "total": 0.06995019999999386,
                    "count": 1,
                    "self": 0.0056597999999894455,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.06429040000000441,
                            "count": 1,
                            "self": 0.06429040000000441
                        }
                    }
                }
            }
        }
    }
}